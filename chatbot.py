import streamlit as st
import time
from openai import OpenAI
import os

def load_prompt(chatbot_type, topic, language):
    type_key = "dpl" if chatbot_type == "ë„í”Œê°±ì–´ ì±—ë´‡" else "gen"
    topic_key = "mtl" if topic == "ì •ì‹  ê±´ê°•" else "rel"
    lang_key = "kor" if language == "í•œêµ­ì–´" else "eng"
    path = f"prompts/{lang_key}/{type_key}_{topic_key}.txt"

    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read() 
    except FileNotFoundError:
        return f"[ERROR] í”„ë¡¬í”„íŠ¸ íŒŒì¼ {path} ì—†ìŒ"

def run(user_name, profile, chatbot_type, topic, language):
    client = OpenAI(api_key=st.secrets["openai"]["api_key"])

    # ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "intro_done" not in st.session_state:
        st.session_state.intro_done = False
    if "awaiting_response" not in st.session_state:
        st.session_state.awaiting_response = False

    st.title("ğŸ§  AITwinBot ëŒ€í™” ì‹œì‘")

    # ì¸íŠ¸ë¡œ ë©”ì‹œì§€ 4ê°œ ì¶œë ¥ (1íšŒë§Œ)
    if not st.session_state.intro_done:
        intro_messages = [
            f"{user_name}, ì•ˆë…•! ë‚˜ëŠ” ë„ˆì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ë„ˆì˜ AITwinBotì´ì•¼. ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ!",
            "ë³¸ê²©ì ìœ¼ë¡œ ì‹œì‘í•˜ê¸° ì „ì—, ìš°ë¦¬ ëŒ€í™”ê°€ ì–´ë–»ê²Œ ì§„í–‰ë ì§€ ê°„ë‹¨íˆ ì„¤ëª…í• ê²Œ.",
            "ë‚´ê°€ íŠ¹ì • ì£¼ì œì— ëŒ€í•´ ëª‡ ê°€ì§€ ë¬¼ì–´ë³¼ê²Œ. ê·¸ê±¸ ë°”íƒ•ìœ¼ë¡œ, ì´ ì£¼ì œì— ëŒ€í•œ ë‚´ ìƒê°ì„ ì„¸ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì–˜ê¸°í• ê±°ì•¼. ë§ˆì§€ë§‰ì—” ëŒ€í™”ê°€ ì–´ë• ëŠ”ì§€ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì„¤ë¬¸ ë§í¬ë¥¼ ì•Œë ¤ ì¤„ê²Œ. ê¼­ ì°¸ì—¬í•´ ì¤˜!",
            "ì¢‹ì•„, ê·¸ëŸ¼ ì‹œì‘í• ê²Œ! ğŸ˜Š"
        ]
        for msg in intro_messages:
            st.session_state.chat_history.append(("ğŸ¤–", msg))
            st.markdown(f"**ğŸ¤–** {msg}")
            time.sleep(1.0)

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚½ì…
        base_prompt = load_prompt(chatbot_type, topic, language)
        full_prompt = (base_prompt.strip()
        + "\n\n---------------------\nKnowledge Section:\n"
        + profile
        )
        st.session_state.messages.append({"role": "system", "content": full_prompt})

        # ì±—ë´‡ ì²« ì‘ë‹µ ìƒì„±
        with st.spinner("ğŸ¤– ì±—ë´‡ì´ ì‘ë‹µ ì¤‘ì´ì—ìš”..."):
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=st.session_state.messages,
                temperature=1,
                max_tokens=2048
            )
        first_reply = response.choices[0].message.content
        st.session_state.chat_history.append(("ğŸ¤–", first_reply))
        st.session_state.messages.append({"role": "assistant", "content": first_reply})

        st.session_state.intro_done = True
        st.rerun()

    # ì´ì „ ëŒ€í™” ì¶œë ¥
    for speaker, msg in st.session_state.chat_history:
        st.markdown(f"**{speaker}** {msg}")

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    if user_input:
        st.session_state.chat_history.append(("ğŸ‘¤", user_input))
        st.session_state.messages.append({"role": "user", "content": user_input})

        # ì‘ë‹µ ìƒì„±
        with st.spinner("ğŸ¤– ì±—ë´‡ì´ ì‘ë‹µ ì¤‘ì´ì—ìš”..."):
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=st.session_state.messages,
                temperature=1,
                max_tokens=2048
            )
        reply = response.choices[0].message.content

        st.session_state.chat_history.append(("ğŸ¤–", reply))
        st.session_state.messages.append({"role": "assistant", "content": reply})
        st.rerun()
