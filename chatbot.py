import streamlit as st
import time
from openai import OpenAI

# ğŸ‘‰ ìŠ¤íƒ€ì¼: ì±—ë´‡/ì‚¬ìš©ì ë§í’ì„  ì˜ˆì˜ê²Œ ë§Œë“¤ê¸°
st.markdown("""
<style>
.chat-container {
    display: flex;
    margin: 6px 0;
}
.chat-bubble {
    padding: 10px 14px;
    border-radius: 12px;
    font-size: 16px;
    line-height: 1.5;
    max-width: 80%;
}
.chat-left {
    justify-content: flex-start;
}
.chat-right {
    justify-content: flex-end;
    text-align: right;
}
.bot-bubble {
    background-color: #e3f2fd;
    color: #2e7d32;
}
.user-bubble {
    background-color: #fcf0c5;
    color: #1565c0;
}
.icon {
    font-size: 20px;
    margin-right: 8px;
    margin-top: 3px;
}
</style>
""", unsafe_allow_html=True)

# ğŸ‘‰ ë©”ì‹œì§€ ë Œë”ë§ í•¨ìˆ˜
def render_message(speaker, msg):
    if speaker == "ğŸ¤–":
        icon = "ğŸ¤–"
        align = "chat-left"
        bubble = "bot-bubble"
    else:
        icon = "ğŸ‘¤"
        align = "chat-right"
        bubble = "user-bubble"

    html = f"""
    <div class="chat-container {align}">
        <div class="chat-bubble {bubble}">
            <span class="icon">{icon}</span> {msg}
        </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

# ğŸ‘‰ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
def load_prompt(chatbot_type, topic, language):
    type_key = "dpl" if chatbot_type == "ë„í”Œê°±ì–´ ì±—ë´‡" else "gen"
    topic_key = "mtl" if topic == "ì •ì‹  ê±´ê°•" else "rel"
    lang_key = "kor" if language == "í•œêµ­ì–´" else "eng"
    path = f"prompts/{lang_key}/{type_key}_{topic_key}.txt"

    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return f"[ERROR] í”„ë¡¬í”„íŠ¸ íŒŒì¼ {path} ì—†ìŒ"

# ğŸ‘‰ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def run(user_name, profile, chatbot_type, topic, language):
    client = OpenAI(api_key=st.secrets["openai"]["api_key"])

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    for key, default in {
        "messages": [],
        "chat_history": [],
        "intro_done": False,
        "awaiting_response": False,
        "pending_user_input": None
    }.items():
        if key not in st.session_state:
            st.session_state[key] = default

    st.title("ğŸ§  AITwinBot ëŒ€í™” ì‹œì‘")

    # ğŸ‘‰ ì¸íŠ¸ë¡œ ë©”ì‹œì§€ & ì²« system prompt ì„¤ì •
    if not st.session_state.intro_done:
        intro_messages = [
            f"{user_name}, ì•ˆë…•! ë‚˜ëŠ” ë„ˆì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ë„ˆì˜ AITwinBotì´ì•¼. ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ!",
            "ë³¸ê²©ì ìœ¼ë¡œ ì‹œì‘í•˜ê¸° ì „ì—, ìš°ë¦¬ ëŒ€í™”ê°€ ì–´ë–»ê²Œ ì§„í–‰ë ì§€ ê°„ë‹¨íˆ ì„¤ëª…í• ê²Œ.",
            "ë‚´ê°€ íŠ¹ì • ì£¼ì œì— ëŒ€í•´ ëª‡ ê°€ì§€ ë¬¼ì–´ë³¼ê²Œ. ê·¸ê±¸ ë°”íƒ•ìœ¼ë¡œ, ì´ ì£¼ì œì— ëŒ€í•œ ë‚´ ìƒê°ì„ ì„¸ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì–˜ê¸°í• ê±°ì•¼. ë§ˆì§€ë§‰ì—” ëŒ€í™”ê°€ ì–´ë• ëŠ”ì§€ í‰ê°€í•  ìˆ˜ ìˆëŠ” ì„¤ë¬¸ ë§í¬ë¥¼ ì•Œë ¤ ì¤„ê²Œ. ê¼­ ì°¸ì—¬í•´ ì¤˜!",
            "ì¢‹ì•„, ê·¸ëŸ¼ ì‹œì‘í• ê²Œ! ğŸ˜Š"
        ]
        for msg in intro_messages:
            st.session_state.chat_history.append(("ğŸ¤–", msg))
            render_message("ğŸ¤–", msg)
            time.sleep(1.0)

        base_prompt = load_prompt(chatbot_type, topic, language)
        full_prompt = base_prompt.strip() + "\n\n---------------------\nKnowledge Section:\n" + profile
        st.session_state.messages.append({"role": "system", "content": full_prompt})

        # LLM ì²« ì‘ë‹µ
        with st.spinner("ğŸ¤– ì±—ë´‡ì´ ì…ë ¥ ì¤‘ì´ì—ìš”..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-4.1",
                    messages=st.session_state.messages,
                    temperature=1,
                    max_tokens=2048
                )
                first_reply = response.choices[0].message.content
            except Exception as e:
                first_reply = f"[ERROR] ì‘ë‹µ ì‹¤íŒ¨: {e}"

        st.session_state.chat_history.append(("ğŸ¤–", first_reply))
        st.session_state.messages.append({"role": "assistant", "content": first_reply})
        st.session_state.intro_done = True
        st.rerun()

    # ğŸ‘‰ ëŒ€í™” ë Œë”ë§
    for speaker, msg in st.session_state.chat_history:
        render_message(speaker, msg)

    # ğŸ‘‰ ì…ë ¥ â†’ ì…ë ¥ë§Œ ë°›ê³  rerun
    user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    if user_input:
        st.session_state.pending_user_input = user_input
        st.rerun()

    # ğŸ‘‰ ì…ë ¥ â†’ ì‚¬ìš©ì ë©”ì‹œì§€ ë¨¼ì € ì¶œë ¥
    if st.session_state.pending_user_input and not st.session_state.awaiting_response:
        user_msg = st.session_state.pending_user_input
        st.session_state.chat_history.append(("ğŸ‘¤", user_msg))
        st.session_state.messages.append({"role": "user", "content": user_msg})
        st.session_state.pending_user_input = None
        st.session_state.awaiting_response = True
        st.rerun()

    # ğŸ‘‰ ì±—ë´‡ ì‘ë‹µ ìƒì„±
    if st.session_state.awaiting_response:
        with st.spinner("ğŸ¤– ì±—ë´‡ì´ ì…ë ¥ ì¤‘ì´ì—ìš”..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-4.1",
                    messages=st.session_state.messages,
                    temperature=1,
                    max_tokens=2048
                )
                reply = response.choices[0].message.content
            except Exception as e:
                reply = f"[ERROR] ì‘ë‹µ ì‹¤íŒ¨: {e}"

        st.session_state.chat_history.append(("ğŸ¤–", reply))
        st.session_state.messages.append({"role": "assistant", "content": reply})
        st.session_state.awaiting_response = False
        st.rerun()
