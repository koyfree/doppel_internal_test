import streamlit as st
import time
from openai import OpenAI

# âœ… ì¢…ë£Œ ë©˜íŠ¸ (ëª¨ë¸ì´ ì´ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë§í•¨)
END_CUE = (
    "Thatâ€™s all from me for now! Hope our talk helped, even just a little. You can share what the experience was like for you on the next page!"
)

# ğŸ‘‰ ë©”ì‹œì§€ ë Œë”ë§ í•¨ìˆ˜
def render_message(speaker, msg):
    if speaker == "ğŸ¤–":
        icon = "ğŸ¤–"
        align = "chat-left"
        bubble = "bot-bubble"
    else:
        icon = "ğŸ‘¤"
        align = "chat-right"
        bubble = "user-bubble"

    html = f"""
    <div class="chat-container {align}">
      <div class="chat-bubble {bubble}">
        <span class="icon">{icon}</span>
        {msg}
      </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

# ğŸ‘‰ í”„ë¡¬í”„íŠ¸ ë¡œë”© í•¨ìˆ˜ (ì´ì œ base_promptë§Œ ë°˜í™˜: ì§€ì‹ í¬í•¨ X)
def load_prompt(chatbot_type, topic, language):
    type_key = "dpl" if chatbot_type == "ë„í”Œê°±ì–´ ì±—ë´‡" else "gen"
    topic_key = "mtl" if topic == "ì •ì‹  ê±´ê°•" else "rel"
    lang_key = "eng"
    path = f"prompts/{lang_key}/{type_key}_{topic_key}.txt"
    try:
        with open(path, "r", encoding="utf-8") as f:
            base_prompt = f.read()
    except FileNotFoundError:
        base_prompt = "[ERROR] No Prompt File"
    return base_prompt.strip()

# ğŸ‘‰ ì´ˆê¸° ë©”ì‹œì§€ ë¹Œë“œ (B í…œí”Œë¦¿ì²˜ëŸ¼ ë¶„ë¦¬)
def build_initial_messages(base_prompt, profile):
    return [
        {
            "role": "system",
            "content": [
                {"type": "text", "text": base_prompt}
            ],
        },
        {
            "role": "user",
            "content": [
                {"type": "text", "text": f"Knowledge Section:\n{profile}"}
            ],
        },
    ]

# ğŸ‘‰ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def run(user_name, profile, chatbot_type, topic, language):
    client = OpenAI(api_key=st.secrets["openai"]["api_key"])

    st.markdown(
        """
        <style>
        body, div, span, input, textarea {
          font-family: "Noto Sans", "Noto Color Emoji", "Apple Color Emoji", "Segoe UI Emoji", sans-serif !important;
        }
        .chat-container { display: flex; margin: 6px 0; }
        .chat-bubble { padding: 10px 14px; border-radius: 12px; font-size: 16px; line-height: 1.5; max-width: 80%; }
        .chat-left { justify-content: flex-start; }
        .chat-right { justify-content: flex-end; text-align: right; }
        .bot-bubble { background-color: #e3f2fd; color: #484848; }
        .user-bubble { background-color: #fcf0c5; color: #484848; }
        .icon { font-size: 16px; margin-right: 8px; margin-top: 3px; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    for key, default in {
        "messages": [],
        "chat_history": [],
        "intro_done": False,
        "awaiting_response": False,
        "pending_user_input": None,
        "interview_phase": "chatting",  # ì§„í–‰ ìƒíƒœ
    }.items():
        if key not in st.session_state:
            st.session_state[key] = default

    st.title("ğŸ§  TwinBotê³¼ì˜ ëŒ€í™”")
    st.markdown(
        f"""
**ğŸ™‹ ì‚¬ìš©ì ì´ë¦„:** {user_name}  
**ğŸ§  ì±—ë´‡ ìœ í˜•:** {chatbot_type}  
**ğŸ’¬ ëŒ€í™” ì£¼ì œ:** {topic}  
**âš™ï¸ ì‚¬ìš© ëª¨ë¸:** {st.session_state.model}
"""
    )

    # âœ… ì¸íŠ¸ë¡œ ë©”ì‹œì§€ & ì²« ì‘ë‹µ
    if not st.session_state.intro_done:
        intro_messages = [
            f"{user_name}, Hi! Iâ€™m your AI TwinBot, created just for you, based on your data. Nice to meet you!",
            "Today, Iâ€™d love to have a short chat and get a sense of how you've been feeling and thinking lately.",
            "Before we really get started, let me briefly explain how our conversation will go.",
            "To start, I want to hear how you have been lately. Then, Iâ€™ll follow up with a few simple questions to get to know your thoughts and feelings a bit more.",
            "No pressure â€” just share whatever comes to mind, comfortably.",
            "After that, Iâ€™ll share my thoughts in three parts.",
            "Itâ€™d be great if you could give me some feedback along the way on how Iâ€™m doing!",
            "Once our conversation is over, youâ€™ll be asked to fill out a short surveyâ€”please be sure to check it out!",
            "Alright, letâ€™s get started! ğŸ˜Š",
        ]
        for msg in intro_messages:
            st.session_state.chat_history.append(("ğŸ¤–", msg))
            render_message("ğŸ¤–", msg)
            time.sleep(0.5)

        # ğŸ”¹ ë¶„ë¦¬ëœ ë©”ì‹œì§€ë¡œ ì²« í˜¸ì¶œ ì¤€ë¹„
        base_prompt = load_prompt(chatbot_type, topic, language)
        st.session_state.messages = build_initial_messages(base_prompt, profile)

        with st.spinner("ğŸ¤– Twinbot is typing now..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-4.1",
                    messages=st.session_state.messages,
                    temperature=1,
                    max_tokens=2048,
                )
                first_reply = response.choices[0].message.content
            except Exception as e:
                first_reply = f"[ERROR] Fail to respond: {e}"

        st.session_state.chat_history.append(("ğŸ¤–", first_reply))
        st.session_state.messages.append({"role": "assistant", "content": first_reply})
        render_message("ğŸ¤–", first_reply)

        # âœ… ì²« ì‘ë‹µì—ì„œë„ ì¢…ë£Œ ë©˜íŠ¸ ê°ì§€
        if END_CUE in first_reply:
            st.session_state.interview_phase = "done"
        st.session_state.intro_done = True
        st.rerun()

    # âœ… ì´ì „ ëŒ€í™” ë Œë”ë§
    for speaker, msg in st.session_state.chat_history:
        render_message(speaker, msg)

    if st.session_state.interview_phase == "done":
        st.session_state.awaiting_response = False
        st.session_state.pending_user_input = None
        st.markdown("""""")
        st.markdown("""**âœ… ëŒ€í™”ê°€ ì—¬ê¸°ì„œ ë§ˆë¬´ë¦¬ë˜ì—ˆì–´ìš”! ì•„ë˜ ë§í¬ë¥¼ ëˆŒëŸ¬ ì–´ë– ì…¨ëŠ”ì§€ í‰ê°€ ë¶€íƒë“œë¦½ë‹ˆë‹¤!**""")
        st.markdown("""**ğŸ‘‰ [í‰ê°€í•˜ê¸°](https://docs.google.com/forms/d/e/1FAIpQLScgaEChMcfui-9CW_58Yv4jwqP33Pa3iNAIY8xEzF19kFL1qQ/viewform?usp=dialog)**""")
        st.stop()

    # âœ… ì‚¬ìš©ì ì…ë ¥ ê°ì§€ ë° ì²˜ë¦¬
    user_input = st.chat_input("Enter your message.")
    if user_input:
        st.session_state.pending_user_input = user_input
        st.rerun()

    # âœ… ì‚¬ìš©ì ì…ë ¥ â†’ ë Œë”ë§
    if st.session_state.pending_user_input and not st.session_state.awaiting_response:
        msg = st.session_state.pending_user_input
        st.session_state.chat_history.append(("ğŸ‘¤", msg))
        st.session_state.messages.append({"role": "user", "content": msg})
        render_message("ğŸ‘¤", msg)
        st.session_state.pending_user_input = None
        st.session_state.awaiting_response = True
        st.rerun()

    # âœ… ì±—ë´‡ ì‘ë‹µ ì²˜ë¦¬
    if st.session_state.awaiting_response:
        with st.spinner("ğŸ¤– Twinbot is typing now..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-4.1",
                    messages=st.session_state.messages,
                    temperature=1,
                    max_tokens=2048,
                )
                reply = response.choices[0].message.content
            except Exception as e:
                reply = f"[ERROR] Fail to respond: {e}"

        st.session_state.chat_history.append(("ğŸ¤–", reply))
        st.session_state.messages.append({"role": "assistant", "content": reply})
        render_message("ğŸ¤–", reply)

        # âœ… ëë©˜íŠ¸ ê°ì§€
        if END_CUE in reply:
            st.session_state.interview_phase = "done"
            st.session_state.awaiting_response = False
            st.session_state.pending_user_input = None
            st.markdown("""""")
            st.markdown("""**âœ… ëŒ€í™”ê°€ ì—¬ê¸°ì„œ ë§ˆë¬´ë¦¬ë˜ì—ˆì–´ìš”! ì•„ë˜ ë§í¬ë¥¼ ëˆŒëŸ¬ ì–´ë– ì…¨ëŠ”ì§€ í‰ê°€ ë¶€íƒë“œë¦½ë‹ˆë‹¤!**""")
            st.markdown("""**ğŸ‘‰ [í‰ê°€í•˜ê¸°](https://docs.google.com/forms/d/e/1FAIpQLScgaEChMcfui-9CW_58Yv4jwqP33Pa3iNAIY8xEzF19kFL1qQ/viewform?usp=dialog)**""")
        else:
            st.session_state.awaiting_response = False
            st.rerun()
