import streamlit as st
import time
import google.generativeai as genai

# ë©”ì‹œì§€ ë Œë”ë§
def render_message(speaker, msg):
    icon = "ğŸ¤–" if speaker == "ğŸ¤–" else "ğŸ‘¤"
    align = "chat-left" if speaker == "ğŸ¤–" else "chat-right"
    bubble = "bot-bubble" if speaker == "ğŸ¤–" else "user-bubble"

    html = f"""
    <div class="chat-container {align}">
        <div class="chat-bubble {bubble}">
            <span class="icon">{icon}</span> {msg}
        </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

# í”„ë¡¬í”„íŠ¸ ë¡œë”©
def load_prompt(chatbot_type, topic, language, profile):
    type_key = "dpl" if chatbot_type == "ë„í”Œê°±ì–´ ì±—ë´‡" else "gen"
    topic_key = "mtl" if topic == "ì •ì‹  ê±´ê°•" else "rel"
    lang_key = "eng"
    path = f"prompts/{lang_key}/{type_key}_{topic_key}.txt"

    try:
        with open(path, "r", encoding="utf-8") as f:
            base_prompt = f.read()
    except FileNotFoundError:
        base_prompt = "[ERROR] No Prompt File"

    return base_prompt.strip() + "\n\n---------------------\nKnowledge Section:\n" + profile

# ë©”ì¸ ì‹¤í–‰
def run(user_name, profile, chatbot_type, topic, language):
    genai.configure(api_key=st.secrets["gemini"]["api_key"])
    model = genai.GenerativeModel("gemini-2.5-flash")

    st.markdown("""
<style>
body, div, span, input, textarea {
    font-family: "Noto Sans", "Noto Color Emoji", "Apple Color Emoji", "Segoe UI Emoji", sans-serif !important;
}
.chat-container {
    display: flex;
    margin: 6px 0;
}
.chat-bubble {
    padding: 10px 14px;
    border-radius: 12px;
    font-size: 16px;
    line-height: 1.5;
    max-width: 80%;
}
.chat-left {
    justify-content: flex-start;
}
.chat-right {
    justify-content: flex-end;
    text-align: right;
}
.bot-bubble {
    background-color: #e3f2fd;
    color: #484848;
}
.user-bubble {
    background-color: #fcf0c5;
    color: #484848;
}
.icon {
    font-size: 16px;
    margin-right: 8px;
    margin-top: 3px;
}
</style>
""", unsafe_allow_html=True)

    for key, default in {
        "messages": [],
        "chat_history": [],
        "intro_done": False,
        "awaiting_response": False,
        "pending_user_input": None
    }.items():
        if key not in st.session_state:
            st.session_state[key] = default

    st.title("ğŸ§  AITwinBot ëŒ€í™” ì‹œì‘")

    if not st.session_state.intro_done:
        intro_messages = [
            f"{user_name}, Hi! Iâ€™m your AI TwinBot, created based on your data. Nice to meet you!",
            "Before we really get started, let me briefly explain how our conversation will go.",
            "Iâ€™ll ask you a few questions about a specific topic. Based on your answers, Iâ€™ll share my thoughts on that topic in three parts.",
            "Itâ€™d be great if you could give me some feedback along the way on how Iâ€™m doing!",
            "Once our conversation is over, Iâ€™ll share a link to a follow-up surveyâ€”please be sure to check it out!",
            "Alright, letâ€™s get started! ğŸ˜Š"
        ]
        for msg in intro_messages:
            st.session_state.chat_history.append(("ğŸ¤–", msg))
            render_message("ğŸ¤–", msg)
            time.sleep(0.5)

        full_prompt = load_prompt(chatbot_type, topic, language, profile)
        st.session_state.messages = [full_prompt]

        with st.spinner("ğŸ¤– Twinbot is typing now..."):
            try:
                convo = model.start_chat(history=[])
                response = convo.send_message(full_prompt)
                first_reply = response.text
                st.session_state.convo = convo  # ëŒ€í™” ê°ì²´ ì €ì¥
            except Exception as e:
                first_reply = f"[ERROR] Fail to respond: {e}"

        st.session_state.chat_history.append(("ğŸ¤–", first_reply))
        render_message("ğŸ¤–", first_reply)

        st.session_state.intro_done = True
        st.rerun()

    for speaker, msg in st.session_state.chat_history:
        render_message(speaker, msg)

    user_input = st.chat_input("Enter your message.")
    if user_input:
        st.session_state.pending_user_input = user_input
        st.rerun()

    if st.session_state.pending_user_input and not st.session_state.awaiting_response:
        msg = st.session_state.pending_user_input
        st.session_state.chat_history.append(("ğŸ‘¤", msg))
        render_message("ğŸ‘¤", msg)

        st.session_state.pending_user_input = None
        st.session_state.awaiting_response = True
        st.rerun()

    if st.session_state.awaiting_response:
        with st.spinner("ğŸ¤– Twinbot is typing now..."):
            try:
                convo = st.session_state.get("convo")
                if convo is None:
                    convo = model.start_chat(history=[])
                    convo.send_message(st.session_state.messages[0])  # system prompt ë‹¤ì‹œ ë³´ë‚´ê¸°
                    st.session_state.convo = convo
                response = convo.send_message(msg)
                reply = response.text
            except Exception as e:
                reply = f"[ERROR] Fail to respond: {e}"

        st.session_state.chat_history.append(("ğŸ¤–", reply))
        render_message("ğŸ¤–", reply)

        st.session_state.awaiting_response = False
        st.rerun()
