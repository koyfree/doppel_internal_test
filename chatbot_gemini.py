import streamlit as st
import time
from openai import OpenAI

# ğŸ‘‰ ë©”ì‹œì§€ ë Œë”ë§ í•¨ìˆ˜
def render_message(speaker, msg):
    if speaker == "ğŸ¤–":
        icon = "ğŸ¤–"
        align = "chat-left"
        bubble = "bot-bubble"
    else:
        icon = "ğŸ‘¤"
        align = "chat-right"
        bubble = "user-bubble"

    html = f"""
    <div class="chat-container {align}">
        <div class="chat-bubble {bubble}">
            <span class="icon">{icon}</span> {msg}
        </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

# ğŸ‘‰ í”„ë¡¬í”„íŠ¸ ë¡œë”© í•¨ìˆ˜
def load_prompt(chatbot_type, topic, language, profile):
    type_key = "dpl" if chatbot_type == "ë„í”Œê°±ì–´ ì±—ë´‡" else "gen"
    topic_key = "mtl" if topic == "ì •ì‹  ê±´ê°•" else "rel"
    lang_key = "kor" if language == "í•œêµ­ì–´" else "eng"
    path = f"prompts/{lang_key}/{type_key}_{topic_key}.txt"

    try:
        with open(path, "r", encoding="utf-8") as f:
            base_prompt = f.read()
    except FileNotFoundError:
        base_prompt = "[ERROR] No Prompt File"

    return base_prompt.strip() + "\n\n---------------------\nKnowledge Section:\n" + profile

# ğŸ‘‰ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def run(user_name, profile, chatbot_type, topic, language):
    client = OpenAI(api_key=st.secrets["openai"]["api_key"])

    st.markdown("""
<style>
body, div, span, input, textarea {
    font-family: "Noto Sans", "Noto Color Emoji", "Apple Color Emoji", "Segoe UI Emoji", sans-serif !important;
}
.chat-container {
    display: flex;
    margin: 6px 0;
}
.chat-bubble {
    padding: 10px 14px;
    border-radius: 12px;
    font-size: 16px;
    line-height: 1.5;
    max-width: 80%;
}
.chat-left {
    justify-content: flex-start;
}
.chat-right {
    justify-content: flex-end;
    text-align: right;
}
.bot-bubble {
    background-color: #e3f2fd;
    color: #484848;
}
.user-bubble {
    background-color: #fcf0c5;
    color: #484848;
}
.icon {
    font-size: 16px;
    margin-right: 8px;
    margin-top: 3px;
}
</style>
""", unsafe_allow_html=True)
    

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    for key, default in {
        "messages": [],
        "chat_history": [],
        "intro_done": False,
        "awaiting_response": False,
        "pending_user_input": None
    }.items():
        if key not in st.session_state:
            st.session_state[key] = default

    st.title("ğŸ§  AITwinBot ëŒ€í™” ì‹œì‘")

    # âœ… ì¸íŠ¸ë¡œ ë©”ì‹œì§€ & ì²« ì‘ë‹µ
    if not st.session_state.intro_done:
        intro_messages = [
            f"{user_name}, Hi! Iâ€™m your AI TwinBot, created based on your data. Nice to meet you!",
            "Before we really get started, let me briefly explain how our conversation will go.",
            "Iâ€™ll ask you a few questions about a specific topic. Based on your answers, Iâ€™ll share my thoughts on that topic in three parts.",
            "Itâ€™d be great if you could give me some feedback along the way on how Iâ€™m doing!",
            "Once our conversation is over, Iâ€™ll share a link to a follow-up surveyâ€”please be sure to check it out!",
            "Alright, letâ€™s get started! ğŸ˜Š"
        ]
        for msg in intro_messages:
            st.session_state.chat_history.append(("ğŸ¤–", msg))
            render_message("ğŸ¤–", msg)
            time.sleep(0.5)

        full_prompt = load_prompt(chatbot_type, topic, language, profile)
        st.session_state.messages.append({"role": "system", "content": full_prompt})

        with st.spinner("ğŸ¤– Twinbot is typing now..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-4.1",
                    messages=st.session_state.messages,
                    temperature=1,
                    max_tokens=2048
                )
                first_reply = response.choices[0].message.content
            except Exception as e:
                first_reply = f"[ERROR] Fail to respond: {e}"

        st.session_state.chat_history.append(("ğŸ¤–", first_reply))
        st.session_state.messages.append({"role": "assistant", "content": first_reply})
        render_message("ğŸ¤–", first_reply)

        st.session_state.intro_done = True
        st.rerun()

    # âœ… ì´ì „ ëŒ€í™” ë Œë”ë§
    for speaker, msg in st.session_state.chat_history:
        render_message(speaker, msg)

    # âœ… ì‚¬ìš©ì ì…ë ¥ ê°ì§€ ë° ì²˜ë¦¬
    user_input = st.chat_input("Enter your message.")
    if user_input:
        st.session_state.pending_user_input = user_input
        st.rerun()

    # âœ… ì‚¬ìš©ì ì…ë ¥ â†’ ë Œë”ë§
    if st.session_state.pending_user_input and not st.session_state.awaiting_response:
        msg = st.session_state.pending_user_input
        st.session_state.chat_history.append(("ğŸ‘¤", msg))
        st.session_state.messages.append({"role": "user", "content": msg})
        render_message("ğŸ‘¤", msg)

        st.session_state.pending_user_input = None
        st.session_state.awaiting_response = True
        st.rerun()

    # âœ… ì±—ë´‡ ì‘ë‹µ ì²˜ë¦¬
    if st.session_state.awaiting_response:
        with st.spinner("ğŸ¤– Twinbot is typing now..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-4.1",
                    messages=st.session_state.messages,
                    temperature=1,
                    max_tokens=2048
                )
                reply = response.choices[0].message.content
            except Exception as e:
                reply = f"[ERROR] Fail to respond: {e}"

        st.session_state.chat_history.append(("ğŸ¤–", reply))
        st.session_state.messages.append({"role": "assistant", "content": reply})
        render_message("ğŸ¤–", reply)

        st.session_state.awaiting_response = False
        st.rerun()
